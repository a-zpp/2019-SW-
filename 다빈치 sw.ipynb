{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제품명을 입력하세요.\n",
      "\n",
      "초록이\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from pandas import read_table\n",
    "import numpy as np\n",
    "import math\n",
    "from konlpy.tag import Okt\n",
    "from konlpy import jvm, utils\n",
    "okt=Okt()\n",
    "\n",
    "#######################################\n",
    "print(\"제품명을 입력하세요.\\n\")\n",
    "x = input()\n",
    "\n",
    "base_url = 'https://search.daum.net/search?w=blog&DA=PGD&enc=utf8&q={}&m=board&page={}'\n",
    "\n",
    "s = []\n",
    "url = []  # 나중에 필터링거친 주소들을 넣을 리스트\n",
    "\n",
    "blog_link = []  # blog 링크\n",
    "\n",
    "for i in range(1, 5):\n",
    "    url = base_url.format(x, i)\n",
    "    r = requests.get(url)\n",
    "    c = r.content\n",
    "\n",
    "    bsObject = BeautifulSoup(c, \"html.parser\")\n",
    "\n",
    "    body = bsObject.select(\"#blogColl > div.coll_cont > ul > li > div > div > a\")  # script body\n",
    "    for link in body:\n",
    "        blog_link.append(link.get(\"href\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_data = []\n",
    "for i in range(0, len(blog_link)):\n",
    "\n",
    "    url = blog_link[i]\n",
    "    r = requests.get(url)\n",
    "    c = r.content\n",
    "    s = BeautifulSoup(c, \"html.parser\")\n",
    "    s = str(s)\n",
    "    s = re.sub(\"<.+?>\", \"\", s, 0, re.I | re.S)\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    s = s.replace(\"(\", \"\")\n",
    "    s = s.replace(\")\", \"\")\n",
    "    s = s.replace(\":\", \"\")\n",
    "    s = s.replace(\",\", \"\")\n",
    "    s = s.replace('\"', \"\")\n",
    "    s = s.split('.')\n",
    "    result = []\n",
    "    for k in range(0, len(s)):\n",
    "        hangul = re.compile('[^ ㄱ-ㅣ가-힣]+')\n",
    "        result.append(hangul.sub('', s[k]))\n",
    "\n",
    "    sentence = \"\"\n",
    "\n",
    "    for j in range(0, len(result)):\n",
    "        sentence += result[j]\n",
    "\n",
    "    blog_data.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare=[]\n",
    "for i in range(0,len(blog_data)):\n",
    "    sentence_compare=[]\n",
    "    p= okt.pos(blog_data[i])\n",
    "    for a in range(0,len(p)):\n",
    "        if p[a][1]!='Josa' and p[a][1]!='KoreanParticle':\n",
    "            sentence_compare.append(p[a][0])\n",
    "    compare.append(sentence_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_compare = []\n",
    "for i in range(0, len(compare)):  \n",
    "    sentence = \"\"\n",
    "    for j in range(0, len(compare[i])):\n",
    "        sentence =  sentence +\" \" +compare[i][j]\n",
    "    result_compare.append(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaiveBayesClassifier 참조\n",
    "# https://repo.yona.io/yona-projects/yona/post/5\n",
    "# https://gist.github.com/ratsgo/45d6eb4822ae27b01329e3b8c15c8f98\n",
    "\n",
    "from collections import defaultdict\n",
    "from pandas import read_table\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "\n",
    "    def __init__(self, k=0.5):\n",
    "        self.k = k\n",
    "        self.word_probs = []\n",
    "\n",
    "    def load_corpus(self, path):\n",
    "        corpus = read_table(path, sep=',', encoding='utf-8')\n",
    "        corpus = np.array(corpus)\n",
    "        return corpus\n",
    "\n",
    "    def count_words(self, training_set):\n",
    "        # 학습데이터는 영화리뷰 본문(doc), 평점(point)으로 구성\n",
    "        counts = defaultdict(lambda : [0, 0])\n",
    "        for doc, point in training_set:\n",
    "            # 영화리뷰가 text일 때만 카운트\n",
    "            if self.isNumber(doc) is False:\n",
    "                # 리뷰를 띄어쓰기 단위로 토크나이징\n",
    "                words = doc.split()\n",
    "                for word in words:\n",
    "                    counts[word][0 if point > 3.5 else 1] += 1\n",
    "        return counts\n",
    "\n",
    "    def isNumber(self, s):\n",
    "        try:\n",
    "            float(s)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    def word_probabilities(self, counts, total_class0, total_class1, k):\n",
    "        # 단어의 빈도수를 [단어, p(w|긍정), p(w|부정)] 형태로 반환\n",
    "        return [(w,\n",
    "                 (class0 + k) / (total_class0 + 2*k),\n",
    "                 (class1 + k) / (total_class1 + 2*k))\n",
    "                for w, (class0, class1) in counts.items()]\n",
    "\n",
    "    def class0_probability(self, word_probs, doc):\n",
    "        # 별도 토크나이즈 안하고 띄어쓰기로만\n",
    "        docwords = doc.split()\n",
    "\n",
    "        # 초기값은 모두 0으로 처리\n",
    "        log_prob_if_class0 = log_prob_if_class1 = 0.0\n",
    "\n",
    "        # 모든 단어에 대해 반복\n",
    "        for word, prob_if_class0, prob_if_class1 in word_probs:\n",
    "            # 만약 리뷰에 word가 나타나면\n",
    "            # 해당 단어가 나올 log 확률을 더해 줌\n",
    "            if word in docwords:\n",
    "                log_prob_if_class0 += math.log(prob_if_class0)\n",
    "                log_prob_if_class1 += math.log(prob_if_class1)\n",
    "\n",
    "            # 만약 리뷰에 word가 나타나지 않는다면\n",
    "            # 해당 단어가 나오지 않을 log 확률을 더해 줌\n",
    "            # 나오지 않을 확률은 log(1-나올 확률)로 계산\n",
    "            else:\n",
    "                log_prob_if_class0 += math.log(1.0 - prob_if_class0)\n",
    "                log_prob_if_class1 += math.log(1.0 - prob_if_class1)\n",
    "\n",
    "        prob_if_class0 = math.exp(log_prob_if_class0)\n",
    "        prob_if_class1 = math.exp(log_prob_if_class1)\n",
    "        return prob_if_class0 / (prob_if_class0 + prob_if_class1)\n",
    "\n",
    "    def train(self, trainfile_path):\n",
    "        training_set = self.load_corpus(trainfile_path)\n",
    "\n",
    "        # 범주0(긍정)과 범주1(부정) 문서 수를 세어 줌\n",
    "        num_class0 = len([1 for _, point in training_set if point > 3.5])\n",
    "        num_class1 = len(training_set) - num_class0\n",
    "\n",
    "        # train\n",
    "        word_counts = self.count_words(training_set)\n",
    "        self.word_probs = self.word_probabilities(word_counts,\n",
    "                                                  num_class0,\n",
    "                                                  num_class1,\n",
    "                                                  self.k)\n",
    "\n",
    "    def classify(self, doc):\n",
    "        return self.class0_probability(self.word_probs, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "총 블로그 수 :  40\n",
      "실제 구매후기 블로그 수 :  10\n",
      "\n",
      "\n",
      "<블로그 URL>\n",
      "http://blog.naver.com/PostView.nhn?blogId=taemoms&logNo=221671576166\n",
      "http://blog.naver.com/PostView.nhn?blogId=whitesoon1&logNo=221673072772\n",
      "http://blog.naver.com/PostView.nhn?blogId=heimish94&logNo=221696548987\n",
      "http://blog.naver.com/PostView.nhn?blogId=yeomi_snap&logNo=221695329978\n",
      "http://blog.naver.com/PostView.nhn?blogId=nieah914&logNo=221686600038\n",
      "http://blog.naver.com/PostView.nhn?blogId=pdyi&logNo=221697635352\n",
      "http://blog.naver.com/PostView.nhn?blogId=leslie818&logNo=221677929753\n",
      "http://blog.naver.com/PostView.nhn?blogId=lua910&logNo=221666799888\n",
      "http://blog.naver.com/PostView.nhn?blogId=verymore9986&logNo=221701579851\n",
      "http://blog.naver.com/PostView.nhn?blogId=stream_chung&logNo=221693102898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oink0\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "blog_date=[]\n",
    "blog_date=result_compare\n",
    "    \n",
    "model = NaiveBayesClassifier()\n",
    "\n",
    "model.train(trainfile_path=r'D:\\add.csv')\n",
    "a = []\n",
    "for i in range(0, len(blog_data)):\n",
    "    a.append(model.classify(blog_data[i]))\n",
    "\n",
    "# print(a)\n",
    "\n",
    "final_blog_link = []\n",
    "for i in range(0, len(blog_data)):\n",
    "    if a[i] < 0.2:\n",
    "        final_blog_link.append(blog_link[i])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"총 블로그 수 : \", len(blog_link))\n",
    "print(\"실제 구매후기 블로그 수 : \", len(final_blog_link))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"<블로그 URL>\")\n",
    "for i in range(0, len(final_blog_link)):\n",
    "    print(final_blog_link[i])\n",
    "#\n",
    "#\n",
    "#\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
